{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3Ft0VrUcO6H71UGUvLX7B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waleed-durrani/gen-ai-360/blob/main/GenAI_360_LangChain_101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Gen AI 360**: Foundational Model Certification ✈\n",
        "\n",
        "## **LangChain & Vector Databases in Production**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "7taLjBh-nI2d"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iD2ya8CvpsrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Required API Tokens:\n",
        "\n",
        "- [OpenAI API Token](https://platform.openai.com/playground): Create the account and generate API Key.\n",
        "- [Deep Lake API Token](https://app.activeloop.ai/register): Create the account and generate API Key.\n",
        "\n",
        "**Note:** Use .env file to store the API keys. And then save the file in Google Drive, mount it, and then use it. Or directly upload it without mounting Google Drive."
      ],
      "metadata": {
        "id": "n_46TTNbpyb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install virtualenv"
      ],
      "metadata": {
        "id": "LmMnam3TKk_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!virtualenv venv"
      ],
      "metadata": {
        "id": "UENuM7K2Kt6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!source venv/bin/activate"
      ],
      "metadata": {
        "id": "UPdiL4u2K6rG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install dotenv package to work with .env(Environmental Variables):"
      ],
      "metadata": {
        "id": "zHv-zOhHaMfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "id": "ktpeX421-uwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Required Packages:\n",
        "\n",
        "Try using latest versions of the following packages except langchain. For smooth practical, try using specified version of LangChain:\n",
        "\n",
        "- langchain==0.0.208 (Course's code is tested on this version)\n",
        "- deeplake\n",
        "- openai\n",
        "- tiktoken\n",
        "\n",
        "`!pip install langchain==0.0.208 deeplake openai tiktoken`\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "WuwYwFJZg8bM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the following code to install required packages:"
      ],
      "metadata": {
        "id": "0OeT2CXu4rE8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Rml295efIrJ"
      },
      "outputs": [],
      "source": [
        "!pip install langchain==0.0.208 deeplake openai tiktoken -qq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv())\n",
        "\n",
        "openai.api_key  = os.getenv('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "ztPc8dW2_m7W"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LangChain's Fundamental Concept: Invoking an LLM with a Specific Input:"
      ],
      "metadata": {
        "id": "KpS_7_-V0bZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing required modules\n",
        "import langchain\n",
        "import openai\n",
        "import tiktoken\n",
        "import deeplake\n",
        "\n",
        "# importing langchain's OpenAI class\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "QvnVEMvlJTcp"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# connect OpenAI key saved in the “OPENAI_API_KEY” environment variable.\n",
        "# using one of GPT-3's variants, called text-davinci-003.\n",
        "# higher temperature = more diverse and unexpected text (can also means more error)\n",
        "\n",
        "llm = OpenAI(model=\"text-davinci-003\", temperature=0.7)"
      ],
      "metadata": {
        "id": "CmVoOjV7NCKc"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Suggest a personalized workout routine for someone looking to improve cardiovascular endurance and prefers outdoor activities.\"\n",
        "print(llm(text))"
      ],
      "metadata": {
        "id": "XYlW-y29eU27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using a different variant of GPT-3, called text-curie-001.\n",
        "llm = OpenAI(model=\"text-curie-001\", temperature=0.3)"
      ],
      "metadata": {
        "id": "4F6THyLegxrc"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt Design Idea from \"ChatGPT Prompt Engineering for Developers\" by DeepLearning.AI and OpenAI\n",
        "\n",
        "text = f\"\"\"Hey, I am a good human being. You got that? And one more thing, you need to understand the\n",
        "consequences before you spit out something from your mouth\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"Use the professional tone to turn text delimited by triple backticks into formal english.\n",
        "```{text}```\n",
        "\"\"\"\n",
        "\n",
        "print(llm(prompt))"
      ],
      "metadata": {
        "id": "LNnE3DlsrNwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chains in LangChain"
      ],
      "metadata": {
        "id": "SzLWPazX5mVG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Company name generation based on products they sell"
      ],
      "metadata": {
        "id": "VuFgHyr8Itse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "# specifying LLM settings (which llm, and the degree of randomness), using OpenAI class from LangChain\n",
        "llm = OpenAI(model=\"text-davinci-003\", temperature=0.9)\n",
        "\n",
        "# langchain's PromtTemplate class: To create dynamic prompts that incorporate user input.\n",
        "# define a template with input variables and fill them with actual values when generating the prompt\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"product\"],\n",
        "    template=\"What is a good name for a company that makes {product}?\",\n",
        ")\n",
        "\n",
        "# takes LLM Object (Chat Model or LLM), and PromptTemplate object\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "\n",
        "# Run the chain only specifying the input variable.\n",
        "print(chain.run(\"Eco-friendly makeup\"))\n",
        "\n",
        "# print(chain.prompt.input_variables[0])"
      ],
      "metadata": {
        "id": "ZaYf9Tiyfhhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Writes a story using inputs (genre, character, setting) from users"
      ],
      "metadata": {
        "id": "skvztwXCMnRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "# specifying LLM settings (which llm, and the degree of randomness), using OpenAI class from LangChain\n",
        "llm = OpenAI(model=\"text-davinci-003\", temperature=0.9)\n",
        "\n",
        "# langchain's PromtTemplate class: To create dynamic prompts that incorporate user input.\n",
        "# define a template with input variables and fill them with actual values when generating the prompt\n",
        "prompt = PromptTemplate(\n",
        "\n",
        "    input_variables=[\"genre\", \"character\", \"setting\"],\n",
        "\n",
        "    template=\"Write a {genre} story about {character}, and {setting}. Use 50 words at the most.\",\n",
        ")\n",
        "\n",
        "\n",
        "# takes LLM Object (Chat Model or LLM), and PromptTemplate object\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "# Use the input() function to take input from the user for each input variable\n",
        "genre = input(\"Enter a genre: \")\n",
        "character = input(\"Enter a character: \")\n",
        "setting = input(\"Enter a setting: \")\n",
        "\n",
        "\n",
        "# Use the run() method of the LLMChain object to execute the chain and generate the output\n",
        "output = chain.run(\n",
        "    genre=genre,\n",
        "    character=character,\n",
        "    setting=setting\n",
        ")\n",
        "\n",
        "# Print the output\n",
        "print(output)\n",
        "\n",
        "# Run the chain only specifying the input variable.\n",
        "# print(chain.run(\"Eco-friendly makeup\"))"
      ],
      "metadata": {
        "id": "qZe98aL872Te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Conversation memory in LangChain"
      ],
      "metadata": {
        "id": "Wucx5WZDQSjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "llm = OpenAI(model=\"text-davinci-003\", temperature=0)\n",
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    memory=ConversationBufferMemory()\n",
        ")\n",
        "\n",
        "# Start the conversation\n",
        "conversation.predict(input=\"Tell me about yourself.\")\n",
        "\n",
        "# Continue the conversation\n",
        "conversation.predict(input=\"What can you do?\")\n",
        "conversation.predict(input=\"How can you help me with data analysis?\")\n",
        "\n",
        "# Display the conversation\n",
        "print(conversation)"
      ],
      "metadata": {
        "id": "NQ92ng07o6GA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZN7auvdlz-dc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}